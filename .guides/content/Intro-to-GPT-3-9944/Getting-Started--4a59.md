Chat models take a series of messages as input, and return a model-generated message as output.

While the chat format of OpenAI's API is primarily intended to facilitate multi-turn conversations, it can be equally effective for handling single-turn tasks that don't involve any back-and-forth interaction. In fact, this capability makes it a viable alternative to traditional instruction-following models like text-davinci-003, which are optimized for generating a single response to a given prompt. Lets get started, In order to begin interacting with the API, we first need to get our libraries.
```python
import os
import openai
import secret
openai.api_key=secret.api_key
```

{Try It!}(python3 temp.py)

Next step in order to generate a response we can use  `openai.ChatCompletion.create` as a function. The function requires two arguments: A response, and a message. For the model throughout this course, we will use the following:`model="gpt-3.5-turbo"`.

```python
response=openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
```


When you use the OpenAI Chat API, you'll need to provide some input for the program to work with. The main input is called "messages," which is a fancy word for a list of things people say to each other in a conversation. You can have as few or as many messages as you want, depending on how long you want the conversation to be.

|||
Each message in the list should have two pieces of information: who said it (**either the "system," the "user," or the "assistant**") and what they said (the actual words they used). 
|||

Lets try generating a response from our API.
```python
response=openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "can you write me 3 senteces on animal behavior."}
    ]
)
```

{Try It!}(python3 temp.py 3)
Typically, a conversation is formatted with a system message first, followed by alternating user and assistant messages.
After pasting the following code, we should get a message saying the code was successfully executed. In order to print, our response we are going to run the following:
```python3 
print(response['choices'][0]['message']['content'].strip())
```
{Try It!}(python3 temp.py 4)


We use the `print` statement to essentially outputs the text generated by the OpenAI language model in response to the user's message specified in the messages parameter.

Switch out the print statement to the following:
``` python
print(response)
```

{Try It!}(python3 temp.py 2)

The response generated is longer and a little harder to quickly decipher. However, now we can understand  the longer print statement we will use. The `print` statement extracts the text content of the response generated by the OpenAI model. It does this by indexing into the response dictionary using the keys 'choices', 0, 'message', and 'content' to access the text content of the first response choice returned by the model. The `strip()` method is then applied to remove any leading or trailing whitespace from the text content before it is printed to the console. 

{Check It!|assessment}(multiple-choice-371114206)
